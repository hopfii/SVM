% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{nty/global//global/global}
  \entry{platt_sequential_1998}{report}{}
    \name{author}{1}{}{%
      {{hash=PJ}{%
         family={Platt},
         familyi={P\bibinitperiod},
         given={John},
         giveni={J\bibinitperiod},
      }}%
    }
    \strng{namehash}{PJ1}
    \strng{fullhash}{PJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{P}
    \field{sortinithash}{P}
    \field{abstract}{%
    This paper proposes a new algorithm for training support vector machines:
  Sequential Minimal Optimization , or {SMO} . Training a support vector
  machine requires the solution of a very large quadratic programming ({QP})
  optimization problem. {SMO} breaks this large {QP} problem into a series of
  smallest possible {QP} problems. These small {QP} problems are solved
  analytically, which avoids using a time-consuming numerical {QP} optimization
  as an inner loop. The amount of memory required for {SMO} is linear in the
  training set size, which allows {SMO} to handle very large training sets.
  Because matrix computation is avoided, {SMO} scales somewhere between linear
  and quadratic in the training set size for various test problems, while the
  standard chunking {SVM} algorithm scales somewhere between linear and cubic
  in the training set size. {SMO}'s computation time is dominated by {SVM}
  evaluation, hence {SMO} is fastest for linear {SVMs} and sparse data sets. On
  real- world sparse data sets, {SMO} can be more than 1000 times faster than
  the chunking algorithm.%
    }
    \field{number}{{MSR}-{TR}-98-14}
    \field{pages}{21}
    \field{title}{Sequential Minimal Optimization: A Fast Algorithm for
  Training Support Vector Machines}
    \verb{url}
    \verb https://www.microsoft.com/en-us/research/publication/sequential-minim
    \verb al-optimization-a-fast-algorithm-for-training-support-vector-machines
    \verb /
    \endverb
    \field{month}{04}
    \field{year}{1998}
  \endentry
\enddatalist
\endinput
